# -*- coding: utf-8 -*-
"""customer churn rate analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxzir8fTnOMT0-DEsrOPlNt6yKVbcJW-
"""

import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

# Load our data into a DataFrame
df = pd.read_csv('churn.csv')

# See a preview:
print(df.head(10))

# Look at the dimensions of our DataFrame
print('Shape:\n', df.shape, '\n')

# List all the column titles in our table:
print('Columns:\n', df.columns.values, '\n')

# Check columns for missing values:
print('Missing Values:\n', df.isna().sum(), '\n')

# Summary Statistics:
print(df.describe(), '/n')

# Get customer churn count:
print('\n--Churn Value Counts--\n', df['Churn'].value_counts())

# Create a bar graph of our count:
sns.countplot(data=df, x='Churn').set(title="Churn Rate Count")

# Define yes/no conditions:
NO = df['Churn'] == 'No'
YES = df['Churn'] == 'Yes'

num_retained = df[NO].shape[0]
num_churned = df[YES].shape[0]

# Percentage of customer that have stayed vs. those who've left:
retain_rate = num_retained/(num_churned + num_retained) * 100
churn_rate = num_churned/(num_churned + num_retained) * 100

print(round(retain_rate, 3), "% of customers stayed.")
print(round(churn_rate, 3), "% of customers left.")

# Create bar graph based on gender:
sns.countplot(data=df, x='gender', hue='Churn')

# Create bar graph based on customer's internet service:
sns.countplot(data=df, x='InternetService', hue='Churn')

numeric_features = ['tenure', 'MonthlyCharges']

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(28, 8))

df[NO][numeric_features].hist(
    bins=20, color='blue', alpha=0.5, ax=ax
)

df[YES][numeric_features].hist(
    bins=20, color='orange', alpha=0.5, ax=ax
)

# Drop the id column:
clean_df = df.drop('customerID', axis=1)

# Convert non-numerical values to numerical:
for col in clean_df.columns:
  if (clean_df[col].dtype == np.number):
    continue
  clean_df[col] = LabelEncoder().fit_transform(clean_df[col])

# See the data types of our columns:
print(clean_df.dtypes)

# Preview our new DataFrame:
print(clean_df.head(10))

# Scale the data set:
x = clean_df.drop('Churn', axis=1)
y = clean_df['Churn']
x = StandardScaler().fit_transform(x)

# Split the data 80 training/20 testing:
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=7)

# Use the logisitic regression algorithm:
model = LogisticRegression()

# Train our model / fit our data:
model.fit(xtrain, ytrain)

# Create predictions from the test data:
predictions = model.predict(xtest)

# See preview of predictions:
print(predictions)

# Create a report of the accuracy of our classifications:
report = classification_report(ytest, predictions)

print(report)